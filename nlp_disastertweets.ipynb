{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a755854",
   "metadata": {},
   "source": [
    "Naive bayes, XGBoost, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e571d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8288e",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3773de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac456478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['text'] = train['location'].astype(str) +\" \" +train['text']\n",
    "# test['text'] = test['location'].astype(str) +\" \" +train['text'] SHIT LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93cda1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['id','keyword', 'location'], axis = 1)\n",
    "# test = test.drop(columns=['id','keyword', 'location'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f908f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean(data):\n",
    "#     data = data.drop(columns=['id','keyword', 'location'], axis = 1) # dropping unwanted columns\n",
    "#     data.text=data.text.apply(lambda x:x.lower()) # converting data to lowercase\n",
    "#     data.text=data.text.apply(lambda x:re.sub('\\[.*?\\]', '', x) ) #removing square brackets\n",
    "#     data.text=data.text.apply(lambda x:re.sub('<.*?>+', '', x) )\n",
    "#     data.text=data.text.apply(lambda x:re.sub('https?://\\S+|www\\.\\S+', '', x) )  #removing hyperlink\n",
    "#     data.text=data.text.apply(lambda x:re.sub('[%s]' % re.escape(string.punctuation), '', x) ) #removing puncuation\n",
    "#     data.text=data.text.apply(lambda x:re.sub('\\n' , '', x) )\n",
    "#     data.text=data.text.apply(lambda x:re.sub('\\w*\\d\\w*' , '', x) ) #remove words containing numbers\n",
    "#     # converting data to string\n",
    "#     for i in range(len(data)):\n",
    "#         data.text[i] = str(data.text[i])\n",
    "# #train.text.head()\n",
    "\n",
    "# df = clean(train)\n",
    "# #clean(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36236b",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "877f561c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN   our deeds are the reason of this earthquake m...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN   all residents asked to shelter in place are b...   \n",
       "3   6     NaN      NaN    people receive wildfires evacuation orders i...   \n",
       "4   7     NaN      NaN   just got sent this photo from ruby alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text=train.text.apply(lambda x:x.lower() )\n",
    "test.text=test.text.apply(lambda x:x.lower())\n",
    "\n",
    "#removing square brackets\n",
    "train.text=train.text.apply(lambda x:re.sub('\\[.*?\\]', '', x) )\n",
    "test.text=test.text.apply(lambda x:re.sub('\\[.*?\\]', '', x) )\n",
    "train.text=train.text.apply(lambda x:re.sub('<.*?>+', '', x) )\n",
    "test.text=test.text.apply(lambda x:re.sub('<.*?>+', '', x) )\n",
    "\n",
    "#removing hyperlink\n",
    "train.text=train.text.apply(lambda x:re.sub('https?://\\S+|www\\.\\S+', '', x) )\n",
    "test.text=test.text.apply(lambda x:re.sub('https?://\\S+|www\\.\\S+', '', x) )\n",
    "#removing puncuation\n",
    "train.text=train.text.apply(lambda x:re.sub('[%s]' % re.escape(string.punctuation), '', x) )\n",
    "test.text=test.text.apply(lambda x:re.sub('[%s]' % re.escape(string.punctuation), '', x) )\n",
    "train.text=train.text.apply(lambda x:re.sub('\\n' , '', x) )\n",
    "test.text=test.text.apply(lambda x:re.sub('\\n', '', x) )\n",
    "#remove words containing numbers\n",
    "train.text=train.text.apply(lambda x:re.sub('\\w*\\d\\w*' , '', x) )\n",
    "test.text=test.text.apply(lambda x:re.sub('\\w*\\d\\w*', '', x) )\n",
    "\n",
    "train.text = train['text'].str.replace('nan', '')\n",
    "test.text = test['text'].str.replace('nan', '')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35293aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-b10448f9c2c6>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.text[i] = str(train.text[i])\n",
      "<ipython-input-53-b10448f9c2c6>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.text[i] = str(test.text[i])\n"
     ]
    }
   ],
   "source": [
    "# train['text'] = str(train['text'])\n",
    "for i in range(7613):\n",
    "    train.text[i] = str(train.text[i])\n",
    "    \n",
    "for i in range(3263):\n",
    "    test.text[i] = str(test.text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eaba6f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [our, deeds, are, the, reason, of, this, earth...\n",
       "1        [forest, fire, near, la, ronge, sask, canada]\n",
       "2    [all, residents, asked, to, shelter, in, place...\n",
       "3    [people, receive, wildfires, evacuation, order...\n",
       "4    [just, got, sent, this, photo, from, ruby, ala...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token=nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "#applying token\n",
    "train.text=train.text.apply(lambda x:token.tokenize(x))\n",
    "test.text=test.text.apply(lambda x:token.tokenize(x))\n",
    "#view\n",
    "display(train.text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "186eee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [deeds, reason, earthquake, may, allah, forgiv...\n",
       "1        [forest, fire, near, la, ronge, sask, canada]\n",
       "2    [residents, asked, shelter, place, notified, o...\n",
       "3    [people, receive, wildfires, evacuation, order...\n",
       "4    [got, sent, photo, ruby, alaska, smoke, wildfi...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "#removing stop words\n",
    "train.text=train.text.apply(lambda x:[w for w in x if w not in stopwords.words('english')])\n",
    "test.text=test.text.apply(lambda x:[w for w in x if w not in stopwords.words('english')])\n",
    "\n",
    "#view\n",
    "train.text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1825fe8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            deed reason earthquak may allah forgiv us\n",
       "1                 forest fire near la rong sask canada\n",
       "2    resid ask shelter place notifi offic evacu she...\n",
       "3          peopl receiv wildfir evacu order california\n",
       "4    got sent photo rubi alaska smoke wildfir pour ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "train.text=train.text.apply(lambda x:\" \".join(stemmer.stem(token) for token in x))\n",
    "test.text=test.text.apply(lambda x:\" \".join(stemmer.stem(token) for token in x))\n",
    "\n",
    "#View\n",
    "train.text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91103d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors= [nltk.word_tokenize(i) for i in train.text]  \n",
    "X_test_vectors= [nltk.word_tokenize(i) for i in test.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "197ba830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = train.text\n",
    "#X_test = test.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aba33c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(train['text']) \n",
    "X_test_vectors_tfidf = tfidf_vectorizer.transform(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5118a1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12426)\t0.2647497827712146\n",
      "  (0, 4351)\t0.460736130793121\n",
      "  (0, 312)\t0.4170447253945454\n",
      "  (0, 7234)\t0.2954351691411343\n",
      "  (0, 3506)\t0.3268540017980149\n",
      "  (0, 9515)\t0.35041026506244183\n",
      "  (0, 2932)\t0.47623590352577255\n",
      "  (1, 1739)\t0.3882998873473426\n",
      "  (1, 10152)\t0.49182490935714945\n",
      "  (1, 9918)\t0.49182490935714945\n",
      "  (1, 6502)\t0.35142353046193325\n",
      "  (1, 7928)\t0.3145471735765239\n",
      "  (1, 4190)\t0.22018178245170175\n",
      "  (1, 4343)\t0.3074431249301026\n",
      "  (2, 3908)\t0.23228019043761372\n",
      "  (2, 8451)\t0.2273094843381881\n",
      "  (2, 3843)\t0.1845362036780636\n",
      "  (2, 8286)\t0.22212503519906254\n",
      "  (2, 8152)\t0.3349256403794359\n",
      "  (2, 8909)\t0.4624599822086023\n",
      "  (2, 10461)\t0.5902472841741969\n",
      "  (2, 666)\t0.24063191047665963\n",
      "  (2, 9700)\t0.28043390876899704\n",
      "  (3, 1706)\t0.3530488267262339\n",
      "  (3, 12927)\t0.37770608758404556\n",
      "  :\t:\n",
      "  (7609, 1706)\t0.24135737996572423\n",
      "  (7609, 4190)\t0.1936358840523296\n",
      "  (7610, 5144)\t0.7555893307430575\n",
      "  (7610, 12644)\t0.6550456192260646\n",
      "  (7611, 8100)\t0.29846856454890786\n",
      "  (7611, 9035)\t0.29846856454890786\n",
      "  (7611, 3528)\t0.5969371290978157\n",
      "  (7611, 2292)\t0.18977765630825985\n",
      "  (7611, 11270)\t0.24645277403539734\n",
      "  (7611, 11785)\t0.24412311042858387\n",
      "  (7611, 5868)\t0.19675434371111847\n",
      "  (7611, 10367)\t0.24645277403539734\n",
      "  (7611, 6810)\t0.20555821680568892\n",
      "  (7611, 5779)\t0.18933040832367132\n",
      "  (7611, 9796)\t0.26534916879116505\n",
      "  (7611, 8989)\t0.17199275473049142\n",
      "  (7611, 1788)\t0.17777896241832977\n",
      "  (7612, 9471)\t0.3972152222253556\n",
      "  (7612, 21)\t0.4157149881839751\n",
      "  (7612, 8127)\t0.3586886561000864\n",
      "  (7612, 6575)\t0.3647162084336905\n",
      "  (7612, 7987)\t0.2956436105683662\n",
      "  (7612, 5374)\t0.31507299413023815\n",
      "  (7612, 1706)\t0.32105225153040395\n",
      "  (7612, 12927)\t0.3434748415964275\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vectors_tfidf) ## transform() = returns document_term matrix. eg (0,12426) = 0th document word 12426. weightage = 0.26474.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e53b352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer() \n",
    "train_vectors_count = count_vectorizer.fit_transform(train['text'])\n",
    "test_vectors_count = count_vectorizer.transform(test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f81e5f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7613x13407 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 65639 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7e5cd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2932)\t1\n",
      "  (0, 9515)\t1\n",
      "  (0, 3506)\t1\n",
      "  (0, 7234)\t1\n",
      "  (0, 312)\t1\n",
      "  (0, 4351)\t1\n",
      "  (0, 12426)\t1\n",
      "  (1, 4343)\t1\n",
      "  (1, 4190)\t1\n",
      "  (1, 7928)\t1\n",
      "  (1, 6502)\t1\n",
      "  (1, 9918)\t1\n",
      "  (1, 10152)\t1\n",
      "  (1, 1739)\t1\n",
      "  (2, 9700)\t1\n",
      "  (2, 666)\t1\n",
      "  (2, 10461)\t2\n",
      "  (2, 8909)\t2\n",
      "  (2, 8152)\t1\n",
      "  (2, 8286)\t1\n",
      "  (2, 3843)\t1\n",
      "  (2, 8451)\t1\n",
      "  (2, 3908)\t1\n",
      "  (3, 3843)\t1\n",
      "  (3, 8451)\t1\n",
      "  :\t:\n",
      "  (7609, 592)\t1\n",
      "  (7609, 11730)\t1\n",
      "  (7610, 12644)\t1\n",
      "  (7610, 5144)\t1\n",
      "  (7611, 1788)\t1\n",
      "  (7611, 8989)\t1\n",
      "  (7611, 9796)\t1\n",
      "  (7611, 5779)\t1\n",
      "  (7611, 6810)\t1\n",
      "  (7611, 10367)\t1\n",
      "  (7611, 5868)\t1\n",
      "  (7611, 11785)\t1\n",
      "  (7611, 11270)\t1\n",
      "  (7611, 2292)\t1\n",
      "  (7611, 3528)\t2\n",
      "  (7611, 9035)\t1\n",
      "  (7611, 8100)\t1\n",
      "  (7612, 12927)\t1\n",
      "  (7612, 1706)\t1\n",
      "  (7612, 5374)\t1\n",
      "  (7612, 7987)\t1\n",
      "  (7612, 6575)\t1\n",
      "  (7612, 8127)\t1\n",
      "  (7612, 21)\t1\n",
      "  (7612, 9471)\t1\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors_count) # (0,2932) = 0th document, word 2932 ocuuring 1 time in the document. (one document can have many lines. like each row of text column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "50060c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77127244, 0.75604053, 0.74760383, 0.74822415, 0.76228209,\n",
       "       0.75396825, 0.75545171, 0.75917065, 0.75851148, 0.75409836,\n",
       "       0.74584323, 0.74451411, 0.76682316, 0.75911252, 0.75862069])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_Vec = MultinomialNB()\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(NB_Vec, train_vectors_count, train[\"target\"], cv=cv, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ebc60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('Vectors', CountVectorizer(stop_words='english')),('tfidf', TfidfTransformer()),\n",
    "     ('NB', MultinomialNB())])\n",
    "pipe.fit(train.text.values, train[\"target\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b58fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=NB_Vec.predict(test_vectors_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9a8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "753a87f4",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d1cd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.4.2-py3-none-win_amd64.whl (97.8 MB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.2.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\programdata\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad828b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=120, leanring_rate=0.075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4322fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"leanring_rate\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             leanring_rate=0.075, learning_rate=0.300000012, max_delta_step=0,\n",
       "             max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=120, n_jobs=8,\n",
       "             num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(train_vectors_count, train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "151c7103",
   "metadata": {},
   "outputs": [],
   "source": [
    "predis = xgb.predict(test_vectors_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "67699912",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= [1 if i>=0.5 else 0 for i in predis]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0ae4913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97fe2f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happen terribl car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heard earthquak differ citi stay safe everyon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire spot pond gees flee across street ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apocalyps light spokan wildfir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>earthquak safeti lo angel ûò safeti fasten xrwn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>storm ri wors last hurrican hardest hit yard l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>green line derail chicago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>meg issu hazard weather outlook hwo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cityofcalgari activ municip emerg plan yycstorm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0                              happen terribl car crash       1  \n",
       "1         heard earthquak differ citi stay safe everyon       1  \n",
       "2     forest fire spot pond gees flee across street ...       1  \n",
       "3                        apocalyps light spokan wildfir       1  \n",
       "4                    typhoon soudelor kill china taiwan       1  \n",
       "...                                                 ...     ...  \n",
       "3258    earthquak safeti lo angel ûò safeti fasten xrwn       1  \n",
       "3259  storm ri wors last hurrican hardest hit yard l...       1  \n",
       "3260                          green line derail chicago       1  \n",
       "3261                meg issu hazard weather outlook hwo       1  \n",
       "3262    cityofcalgari activ municip emerg plan yycstorm       0  \n",
       "\n",
       "[3263 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4cc4ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns=['keyword','location','text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "47cdc0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(r'test_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d2949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "846460c8",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c3b45da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = svm.SVC(kernel = 'linear', gamma='auto')\n",
    "svm_model.fit(train_vectors_count, train['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "13ab69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = svm_model.predict(test_vectors_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4aef2c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "46488b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "52c8f4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d3a86af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(r'test_svm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bab79172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e4238631",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier()\n",
    "predictions_DT=dtree.fit(train_vectors_count, train['target']).predict(test_vectors_count)\n",
    "# print('The accuracy of the Decision Tree is',round(accuracy_score(predictions_DT,y_test)*100,2))\n",
    "# sns.heatmap(confusion_matrix(y_test,predictions_DT),annot=True,fmt='3.0f')\n",
    "# plt.title('Confusion_matrix', y=1.05, size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9ffec19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1831bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = predictions_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e4e6d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(r'test_dt.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
